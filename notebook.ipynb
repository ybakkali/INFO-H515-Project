{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# INTRODUCTION\n",
    "In this notebook we will be using the following packages as bullet list:\n",
    "  * [pyspark](https://spark.apache.org/docs/latest/api/python/pyspark.html)\n",
    "  * [pandas](https://pandas.pydata.org/pandas-docs/stable/index.html)\n",
    "  * [pyarrow](https://arrow.apache.org/docs/python/index.html)\n",
    "\n",
    "We will be using the following data:\n",
    "  * dressipi_recsys2022\n",
    "\n",
    "The dataset is split in 4 csv files :\n",
    "   * candidate_items : contains the candidate items for each user\n",
    "   * item_features : contains the features for each item (items can have multiple features)\n",
    "   * train_purchases : contains the purchases for each user\n",
    "   * train_sessions : contains the sessions for each user\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Uncomment to install the required packages\n",
    "# %pip install pyspark\n",
    "# %pip install pyarrow\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading the dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n"
     ]
    }
   ],
   "source": [
    "# from dataset import *\n",
    "from pipeline import *\n",
    "# from our_model import *\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# start spark session\n",
    "spark = SparkSession.builder.appName(\"Python Spark SQL basic example\").config(\"spark.some.config.option\", \"some-value\").getOrCreate()\n",
    "\n",
    "candidate_items, item_features, train_purchases, train_sessions = [None] * 4\n",
    "datasets = [candidate_items, item_features, train_purchases, train_sessions]\n",
    "\n",
    "#load all datasets\n",
    "def load_candidate_items():\n",
    "    global candidate_items\n",
    "    candidate_items = SPARK.read.csv(\"dressipi_recsys2022/candidate_items.csv\", header=True)\n",
    "    candidate_items = candidate_items.withColumn(\"item_id\", candidate_items[\"item_id\"].cast(\"int\"))\n",
    "\n",
    "def load_item_features():\n",
    "    global item_features\n",
    "    item_features = SPARK.read.csv(\"dressipi_recsys2022/item_features.csv\", header=True)\n",
    "    item_features = item_features.withColumn(\"item_id\", item_features[\"item_id\"].cast(\"int\"))\n",
    "    item_features = item_features.withColumn(\"feature_category_id\", item_features[\"feature_category_id\"].cast(\"int\"))\n",
    "    item_features = item_features.withColumn(\"feature_value_id\", item_features[\"feature_value_id\"].cast(\"int\"))\n",
    "\n",
    "def load_train_purchases():\n",
    "    global train_purchases\n",
    "    train_purchases = SPARK.read.csv(\"dressipi_recsys2022/train_purchases.csv\", header=True)\n",
    "    train_purchases = train_purchases.withColumn(\"session_id\", train_purchases[\"session_id\"].cast(\"int\"))\n",
    "    train_purchases = train_purchases.withColumn(\"item_id\", train_purchases[\"item_id\"].cast(\"int\"))\n",
    "    train_purchases = train_purchases.withColumn(\"date\", train_purchases[\"date\"].cast(\"timestamp\"))\n",
    "\n",
    "def load_train_sessions():\n",
    "    global train_sessions\n",
    "    train_sessions = SPARK.read.csv(\"dressipi_recsys2022/train_sessions.csv\", header=True)\n",
    "    train_sessions = train_sessions.withColumn(\"session_id\", train_sessions[\"session_id\"].cast(\"int\"))\n",
    "    train_sessions = train_sessions.withColumn(\"user_id\", train_sessions[\"item_id\"].cast(\"int\"))\n",
    "    train_sessions = train_sessions.withColumn(\"date\", train_sessions[\"date\"].cast(\"timestamp\"))\n",
    "\n",
    "def load_datasets():\n",
    "    global datasets\n",
    "    load_candidate_items()\n",
    "    load_item_features()\n",
    "    load_train_purchases()\n",
    "    load_train_sessions()\n",
    "    datasets = [candidate_items, item_features, train_purchases, train_sessions]\n",
    "\n",
    "load_datasets()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Quick look at the data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### train_sessions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+--------------------+-------+\n",
      "|session_id|item_id|                date|user_id|\n",
      "+----------+-------+--------------------+-------+\n",
      "|         3|   9655|2020-12-18 21:25:...|   9655|\n",
      "|         3|   9655|2020-12-18 21:19:...|   9655|\n",
      "|        13|  15654|2020-03-13 19:35:...|  15654|\n",
      "|        18|  18316|2020-08-26 19:18:...|  18316|\n",
      "|        18|   2507|2020-08-26 19:16:...|   2507|\n",
      "+----------+-------+--------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_sessions.show(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### train_purchases"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+--------------------+\n",
      "|session_id|item_id|                date|\n",
      "+----------+-------+--------------------+\n",
      "|         3|  15085|2020-12-18 21:26:...|\n",
      "|        13|  18626|2020-03-13 19:36:...|\n",
      "|        18|  24911|2020-08-26 19:20:...|\n",
      "|        19|  12534|2020-11-02 17:16:...|\n",
      "|        24|  13226|2020-02-26 18:27:...|\n",
      "+----------+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_purchases.show(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### item_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+----------------+\n",
      "|item_id|feature_category_id|feature_value_id|\n",
      "+-------+-------------------+----------------+\n",
      "|      2|                 56|             365|\n",
      "|      2|                 62|             801|\n",
      "|      2|                 68|             351|\n",
      "|      2|                 33|             802|\n",
      "|      2|                 72|              75|\n",
      "+-------+-------------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "item_features.show(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### candidate_items"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|item_id|\n",
      "+-------+\n",
      "|      4|\n",
      "|      8|\n",
      "|      9|\n",
      "|     19|\n",
      "|     20|\n",
      "+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "candidate_items.show(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 1 : Pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Checking for null values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_items: 0\n",
      "item_features: 0\n",
      "train_purchases: 0\n",
      "train_sessions: 0\n"
     ]
    }
   ],
   "source": [
    "# Are there missing values (na or null) in any of those dataframes ? print the number of missing values\n",
    "print(\"candidate_items:\", candidate_items.filter(candidate_items[\"item_id\"].isNull()).count())\n",
    "print(\"item_features:\", item_features.filter(item_features[\"item_id\"].isNull()).count())\n",
    "print(\"train_purchases:\", train_purchases.filter(train_purchases[\"item_id\"].isNull()).count())\n",
    "print(\"train_sessions:\", train_sessions.filter(train_sessions[\"item_id\"].isNull()).count())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Normalization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature engineering"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 2 : Algorithms"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Scalable feature selection algorithm 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Scalable feature selection algorithm 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ranking algorithm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Forward feature selection"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 3 : Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[Row(item_id=2, feature_category_id=56, feature_value_id=365), Row(item_id=2, feature_category_id=62, feature_value_id=801), Row(item_id=2, feature_category_id=68, feature_value_id=351), Row(item_id=2, feature_category_id=33, feature_value_id=802), Row(item_id=2, feature_category_id=72, feature_value_id=75), Row(item_id=2, feature_category_id=29, feature_value_id=123), Row(item_id=2, feature_category_id=16, feature_value_id=38), Row(item_id=2, feature_category_id=50, feature_value_id=76), Row(item_id=2, feature_category_id=61, feature_value_id=462), Row(item_id=2, feature_category_id=53, feature_value_id=6), Row(item_id=2, feature_category_id=7, feature_value_id=394), Row(item_id=2, feature_category_id=69, feature_value_id=885), Row(item_id=2, feature_category_id=47, feature_value_id=123)]\n",
      "[]\n",
      "[Row(session_id=3401213, item_id='2', date=datetime.datetime(2021, 3, 28, 8, 24, 15, 321000), user_id=2)]\n"
     ]
    }
   ],
   "source": [
    "# show rows with item_id == 2 in all dataframes\n",
    "for d in datasets:\n",
    "    print(d.filter(d[\"item_id\"] == 2).collect())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}